{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09675fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\e3nn\\o3\\_wigner.py:10: UserWarning: Environment variable TORCH_FORCE_NO_WEIGHTS_ONLY_LOAD detected, since the`weights_only` argument was not explicitly passed to `torch.load`, forcing weights_only=False.\n",
      "  _Jd, _W3j_flat, _W3j_indices = torch.load(os.path.join(os.path.dirname(__file__), 'constants.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuequivariance or cuequivariance_torch is not available. Cuequivariance acceleration will be disabled.\n"
     ]
    }
   ],
   "source": [
    "import ase\n",
    "import mace.calculators\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3ef11",
   "metadata": {},
   "source": [
    "La idea de este Notebook es trabajar con los conceptos de la libreria de MACE, esto como una primer aproximación al proyecto de Aprendizaje Estadistico. En teoria debe existir una segunda parte haciendo lo mismo con la libreria ASE, pues en realidad al importar mace.calculators lo que estamos haciendo es importar un \"CALCULATOR\" de ASE (Atomic Simularion Enviroment) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffd5bf",
   "metadata": {},
   "source": [
    "MACE tiene su documentación para python en \"https://mace-docs.readthedocs.io/en/latest/guide/guide.html\". Página web que funciona similar a la documentación de Matplotlib o de Numpy. Esta posee varias secciones principales, donde cada una tiene algunas secciones secundarias, dando un vistazo por encima observamos:\n",
    "\n",
    "- Troubleshooting and Q&A Guide\n",
    "- Training\n",
    "- Evaluation\n",
    "- Heterogeneous Data Training\n",
    "- ASE Caclulator\n",
    "- MACE descriptors\n",
    "- Analytic Hessians\n",
    "- CUDA Acceleration with cuEquivariance Library\n",
    "- OpenMM Interface\n",
    "- MACE in LAMMPS with ML-IAP\n",
    "- Foundation models\n",
    "- Fine-tuning Foundation Models\n",
    "- Multihead Replay Fine-tuning\n",
    "- Multihead Training for MACE\n",
    "- Larga Dataset Pre-processing\n",
    "- Multi-GPUs Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ba10b",
   "metadata": {},
   "source": [
    "#### Q&A:\n",
    "\n",
    "**Energy reference** (E0s) Problems: - What values should I use for atomic reference energies (E0s)?\n",
    "\n",
    "- DFT refence energies: Use isolated atom energies calculated with exactly the same DFT settings as your dataset.\n",
    "- Avarage E0s: Use `--E0s=avarage` to let MACE determine these values from your.\n",
    "How do I know if my E0s are causing problems?: heck the validation loss. For energy, expected values are:\n",
    "- Good E0s: Initial RMSE of 0.1-4 eV/atom\n",
    "- Problematic E0s: Initial RMSE bigger than 5 eV\n",
    "\n",
    "**Finetuning** Los mejores \"foundation models\" para finetuning son MPA-0 model y OMAT-O model.\n",
    "\n",
    "- Cuando usar Multi-head finetuning? **R/** Es la manera recomendada de hacer ajuste fine si tienes acceso a los recomputed E0s para tu nuevo DFT setting.\n",
    "\n",
    "- How many data should I use for finetuning? **R/** A starting dataset of about 10-50 diverse configurations is recommended for finetuning. An good amount is around 100.\n",
    "\n",
    "- How should I set the hyperparameters for multi-head finetuning? **R/** A good starting point for hyperparameters for multi-head finetuning is:\n",
    "\n",
    "```\n",
    "--ema_decay=0.99999\n",
    "--lr=0.0001\n",
    "--num_samples_pt=100000\n",
    "--forces_weight=10\n",
    "--energy_weight=1\n",
    "--stress_weight=1\n",
    "```\n",
    "\n",
    "**Cutoff Radius Selection** Hace refencia al vecindario (Distancia radial de interacción de cada nodo), lo recomendado esta entre los 6-7 A, donde no se recomienda distancias menores a 4 A.\n",
    "\n",
    "Una vez elegido el radio, reduzcalo en caso de limitaciones de memoria o velocidad de computo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e67d35",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Para realizar el entrenamiento de un modelo MACE se puede usar el script run_train.py \"\\mace\\mace\\cli\\run_train.py\" (ubicación del script en el repo, Tómas te recomiendo hacer un fork del repo y clonarlo en tu dispositivo, \"https://github.com/ACEsuit/mace/tree/main\", este es el enlace) \n",
    "\n",
    "De una vez veo que el script es super super largo, díficil desglosarlo, pero se puede hacer el intento (lo supongo necesario dado nuestro interes partícular con el proyecto)\n",
    "\n",
    "para su ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se define un main()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    This script runs the training/fine tuning for mace\n",
    "    \"\"\"\n",
    "    args = tools.build_default_arg_parser().parse_args()\n",
    "    run(args)\n",
    "\n",
    "# note que el main simplemente llama a run(args) donde args proviene de tools.build_default_arg_parser().parse_args()\n",
    "# tools es una carpeta de MACE, en este existe el script args_parcer.py que contiene la función build_default_arg_parser()\n",
    "# Esta contiene los argumentos por defecto para correr el entrenamiento/fine tuning\n",
    "\n",
    "def run(args) -> None:\n",
    "\n",
    "# Es realmente el código importante, que corre el entrenamiento/fine tuning\n",
    "# Aquí se realiza el entrenamiento a aparit de unos argumentos (por defecto se pueden\n",
    "# emplear los del submodulo tools de MACE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6854f",
   "metadata": {},
   "source": [
    "Usaremos entonces `run_train.py` el que require de los siguientes argumentos:\n",
    "\n",
    "- `--name` : obligarotio y definel el nombre de nuestro archivo\n",
    "- `--train_file`: archivo de entrenamiento \n",
    "- `--valid_file` : archivo de validación, aunque tambien puede ser una fracción del train_file\n",
    "- `--test_file`: Archivo de test para la evaluación del proceso de entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c170283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
